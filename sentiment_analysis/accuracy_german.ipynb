{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load the CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_de \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../Preprocessing/data_clean/labeled-data/labeled-de_clean_1-1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 3\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "#ACTION:Why doesn't this work for me? I checked the link so often and the one below works.\n",
    "df_de = pd.read_csv('../Preprocessing/data_clean/labeled-data/labeled-de_clean_1-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_de_con = pd.read_csv('../Preprocessing/data_clean/labeled-data/labeled-de_clean_condensed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data;player;language;publishedAt;Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trainer alonso mitgereisten fans monaco glucks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sechser droht viereinhalb monaten pause bitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bayerleverkusen sechser erklart budapest spiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bakker mittwoch abschluss training bayerleverk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allerdings andrich argentinischen weltmeister ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              data;player;language;publishedAt;Label\n",
       "0  trainer alonso mitgereisten fans monaco glucks...\n",
       "1  sechser droht viereinhalb monaten pause bitter...\n",
       "2  bayerleverkusen sechser erklart budapest spiel...\n",
       "3  bakker mittwoch abschluss training bayerleverk...\n",
       "4  allerdings andrich argentinischen weltmeister ..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de_con.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DE datasate drop empty lines\n",
    "df_de = df_de.dropna(subset=['data']) #Why in data and not in Label column?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(df):\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "    # Create an empty list to store the sentiment scores\n",
    "    sentiment_scores = []\n",
    "\n",
    "    # Iterate over the 'data' column in the DataFrame\n",
    "    for text in df['data']:\n",
    "        # Tokenize the input text\n",
    "        tokens = tokenizer.encode_plus(text, padding=\"max_length\", truncation=True, max_length=128,\n",
    "                                       return_tensors=\"pt\")\n",
    "\n",
    "        # Perform the sentiment analysis\n",
    "        with torch.no_grad():\n",
    "            logits = model(**tokens)[0]\n",
    "\n",
    "        # Convert logits to predicted label (positive/negative)\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "        sentiment = \"positiv\" if predicted_label == 1 else \"negativ\"\n",
    "\n",
    "        # Append the sentiment score to the list\n",
    "        sentiment_scores.append(sentiment)\n",
    "\n",
    "    # Add the sentiment scores as a new column in the DataFrame\n",
    "    df['sentiment'] = sentiment_scores\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis on the DataFrame\n",
    "df = perform_sentiment_analysis(df_de)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901639344262295"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'] == 'negativ'].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Label']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Drop rows where 'Label' is NaN or empty\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_de\u001b[39m.\u001b[39;49mdropna(subset\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m], inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print the updated DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m df_de[df_de[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:6407\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6405\u001b[0m     check \u001b[39m=\u001b[39m indices \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   6406\u001b[0m     \u001b[39mif\u001b[39;00m check\u001b[39m.\u001b[39many():\n\u001b[1;32m-> 6407\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(np\u001b[39m.\u001b[39marray(subset)[check]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m   6408\u001b[0m     agg_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indices, axis\u001b[39m=\u001b[39magg_axis)\n\u001b[0;32m   6410\u001b[0m \u001b[39mif\u001b[39;00m thresh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m no_default:\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Label']"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_de.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data = df_de[df_de['Label'] != 'neutral']\n",
    "\n",
    "df_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zweimal verwandelte palacios, es wurde ein ube...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-19T20:01:45Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"auf jeden fall\" sei das ein ganz grosser tag,...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-20T20:54:03Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bayerleverkusen argentinischer weltmeister pal...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-14T18:07:21Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>\"es gibt im moment nicht viel besseres in der ...</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-31T07:59:57Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>hincapie (l.) und tah bedanken sich fur die fa...</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-14T08:16:22Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>bayerleverkusen torschutze amiri (rechts) u...</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-23T17:33:57Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>frimpong bekommt gluckwunsche seines trainers ...</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-23T18:00:31Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>selbst als stammkraft frimpong in den vergange...</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-23T10:24:42Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>schalke wiederum hatte durch michael frey ein ...</td>\n",
       "      <td>tah</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-01T15:44:09Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>alonso \"stolz\": werkself seit spielen ungeschl...</td>\n",
       "      <td>tah</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-23T20:48:00Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>torwart lukas hradecky bewahrte bayerleverkuse...</td>\n",
       "      <td>tah</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-11T23:42:49Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>zudem drohen sowohl bakker\\xaals auch weltmeis...</td>\n",
       "      <td>bakker</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-02-23T09:06:07Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>torschutzen unter sich: diaby (links, treffer ...</td>\n",
       "      <td>bakker</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-20T21:15:24Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>beim : hatte mitchell bakker gepatzt</td>\n",
       "      <td>bakker</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-21T19:39:14Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>frimpong wirkt uberspielt, und diaby bewegte s...</td>\n",
       "      <td>diaby</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-12T09:44:10Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>torwart lukas hradecky bewahrte bayerleverkuse...</td>\n",
       "      <td>diaby</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-11T23:42:49Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>zu sehen ist davon wenig - und das liegt nicht...</td>\n",
       "      <td>mudryk</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-19T06:10:46Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>hincapie von fussball-bundesligist bayerleverk...</td>\n",
       "      <td>hincapie</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-23T10:52:44Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>bayerleverkusen torwart lukas hradecky sitzt f...</td>\n",
       "      <td>hincapie</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-02-17T17:14:46Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>in der funften minute der nachspielzeit sah ba...</td>\n",
       "      <td>hincapie</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-05-21T19:53:27Z</td>\n",
       "      <td>negativ</td>\n",
       "      <td>negativ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data    player language  \\\n",
       "14   zweimal verwandelte palacios, es wurde ein ube...  palacios       de   \n",
       "41   \"auf jeden fall\" sei das ein ganz grosser tag,...  palacios       de   \n",
       "63   bayerleverkusen argentinischer weltmeister pal...  palacios       de   \n",
       "83   \"es gibt im moment nicht viel besseres in der ...  frimpong       de   \n",
       "102  hincapie (l.) und tah bedanken sich fur die fa...  frimpong       de   \n",
       "123     bayerleverkusen torschutze amiri (rechts) u...  frimpong       de   \n",
       "124  frimpong bekommt gluckwunsche seines trainers ...  frimpong       de   \n",
       "130  selbst als stammkraft frimpong in den vergange...  frimpong       de   \n",
       "173  schalke wiederum hatte durch michael frey ein ...       tah       de   \n",
       "199  alonso \"stolz\": werkself seit spielen ungeschl...       tah       de   \n",
       "214  torwart lukas hradecky bewahrte bayerleverkuse...       tah       de   \n",
       "223  zudem drohen sowohl bakker\\xaals auch weltmeis...    bakker       de   \n",
       "258  torschutzen unter sich: diaby (links, treffer ...    bakker       de   \n",
       "273               beim : hatte mitchell bakker gepatzt    bakker       de   \n",
       "361  frimpong wirkt uberspielt, und diaby bewegte s...     diaby       de   \n",
       "362  torwart lukas hradecky bewahrte bayerleverkuse...     diaby       de   \n",
       "383  zu sehen ist davon wenig - und das liegt nicht...    mudryk       de   \n",
       "413  hincapie von fussball-bundesligist bayerleverk...  hincapie       de   \n",
       "433  bayerleverkusen torwart lukas hradecky sitzt f...  hincapie       de   \n",
       "436  in der funften minute der nachspielzeit sah ba...  hincapie       de   \n",
       "\n",
       "              publishedAt    Label sentiment  \n",
       "14   2023-03-19T20:01:45Z  positiv   negativ  \n",
       "41   2023-04-20T20:54:03Z  positiv   negativ  \n",
       "63   2023-05-14T18:07:21Z  negativ   negativ  \n",
       "83   2023-03-31T07:59:57Z  positiv   negativ  \n",
       "102  2023-04-14T08:16:22Z  positiv   negativ  \n",
       "123  2023-04-23T17:33:57Z  positiv   negativ  \n",
       "124  2023-04-23T18:00:31Z  positiv   negativ  \n",
       "130  2023-05-23T10:24:42Z  negativ   negativ  \n",
       "173  2023-04-01T15:44:09Z  positiv   negativ  \n",
       "199  2023-04-23T20:48:00Z  positiv   negativ  \n",
       "214  2023-05-11T23:42:49Z  positiv   negativ  \n",
       "223  2023-02-23T09:06:07Z  negativ   negativ  \n",
       "258  2023-04-20T21:15:24Z  positiv   negativ  \n",
       "273  2023-05-21T19:39:14Z  negativ   negativ  \n",
       "361  2023-05-12T09:44:10Z  negativ   negativ  \n",
       "362  2023-05-11T23:42:49Z  negativ   negativ  \n",
       "383  2023-04-19T06:10:46Z  negativ   negativ  \n",
       "413  2023-05-23T10:52:44Z  negativ   negativ  \n",
       "433  2023-02-17T17:14:46Z  negativ   negativ  \n",
       "436  2023-05-21T19:53:27Z  negativ   negativ  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = (data['sentiment'] == data['Label']).mean() * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Perform sentiment analysis on the DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_con \u001b[39m=\u001b[39m perform_sentiment_analysis(df_de_con)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print the updated DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_con\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m, in \u001b[0;36mperform_sentiment_analysis\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m sentiment_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[39m# Iterate over the 'data' column in the DataFrame\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Tokenize the input text\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode_plus(text, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                    return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[39m# Perform the sentiment analysis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "# Perform sentiment analysis on the DataFrame\n",
    "df_con = perform_sentiment_analysis(df_de_con)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con[df_con['sentiment'] == 'negativ'].shape[0]/df_con.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_de_con.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data_con = df_de_con[df_de_con['Label'] != 'neutral']\n",
    "\n",
    "df_de_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy_con = (data_con['sentiment'] == data_con['Label']).mean() * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_con))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
