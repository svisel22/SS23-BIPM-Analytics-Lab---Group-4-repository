{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import remove_similar_rows_per_player, find_lines_with_player, del_patterns, map_emoji_to_description, remove_accents\n",
    "import emoji\n",
    "from googletrans import Translator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/data_files/all_data_v3.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Transformation (with Pattern deletion)\n",
    "The first transformation focus on the deletion of Patterns to clean the corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out German data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the German data and reindex\n",
    "df_ger = df[df[\"language\"] == \"de\"]\n",
    "df_ger = df_ger.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the similiar rows (The Function is imported from utils on top)\n",
    "df = remove_similar_rows_per_player(df_ger, df_ger['player'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into lower case\n",
    "data_lower = df.copy()\n",
    "\n",
    "data_lower['data'] = data_lower['data'].str.lower()\n",
    "data_lower['player'] = data_lower['player'].str.lower()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delte Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete content patterns\n",
    "data_wo_pattern = data_lower.copy()\n",
    "data_wo_pattern['data'] = data_wo_pattern['data'].apply(lambda x: re.sub(r\"^{\\'content\\': \\'\", \"\", str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = ['nutze kicker', \n",
    "           'mit dem', \n",
    "           'nur €2,49', \n",
    "           'bereits pur-abonnent?', \n",
    "           'alle antworten', \n",
    "           'hinweis zur verarbeitung', \n",
    "           'werbung','olympia-verlags', \n",
    "           'bild', 'g+j medien gmbh', \n",
    "           'services',\n",
    "           'kurz-link dieses artikels lautet:', \n",
    "           'http://epaper.welt.de',\n",
    "           'stephan von nocks',\n",
    "           'www.faz.net',\n",
    "           'mcfit mitgliedschaft',\n",
    "           'fitx-vertrag',\n",
    "           'kündigeneasyfitness',\n",
    "           'proteinbedarf',\n",
    "           'fitnessland',\n",
    "           'kündigeneasyfitness',\n",
    "           'trainingspuls berechnen',\n",
    "           'pulsrechner',\n",
    "           'fitseveneleven-mitgliedschaft',\n",
    "           'alkoholabbau & promille',\n",
    "           'index.promillerechner',\n",
    "           'mitgliedschaft kündigen',\n",
    "           'promillerechner',\n",
    "           'ihr body-mass-index',\n",
    "           'bmi rechner',\n",
    "           'kalorienrechner',\n",
    "           'grundumsatz & kalorienbedarf',\n",
    "           'partnerangebote',\n",
    "           'newsletter',\n",
    "           'journalismus der presse',\n",
    "           'abonnieren',\n",
    "           '(apa)',\n",
    "           'foto:',\n",
    "           'quelle:',\n",
    "           'lesezeit:',\n",
    "           'lesen sie mehr',\n",
    "           'stellenmarkt der sz.',\n",
    "           'bewerben sie sich jetzt',\n",
    "           'gutscheine',\n",
    "           'vergleichsportal',\n",
    "           'stern plus-inhalten',\n",
    "           'jederzeit kündbar',\n",
    "           'bereits registriert?',\n",
    "           'zur startseite',\n",
    "           'öffnet in neuem tab oder fenster',\n",
    "           'vollansicht der tabelle unter'        \n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_pattern['data'] = data_wo_pattern['data'].apply(lambda x: del_patterns(str(x), pattern))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Emojis to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_pattern['data'] = data_wo_pattern['data'].apply(lambda x: re.sub(r'[^\\w\\s]', lambda match: map_emoji_to_description(match.group(), language = 'de',), str(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm_1 = data_wo_pattern.copy()\n",
    "\n",
    "# strip_numeric -> removing digits (https://gensimr.news-r.org/reference/strip_numeric.html)\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(strip_numeric)\n",
    "\n",
    "# strip_punctutation -> removing punctations (https://gensimr.news-r.org/reference/strip_punctuation.html)\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(strip_punctuation)\n",
    "\n",
    "# strip multiple whitespaces also \\n -> (https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.strip_multiple_whitespaces)\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(strip_multiple_whitespaces)\n",
    "\n",
    "#strip spanish accents\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(lambda x: remove_accents(str(x)))\n",
    "\n",
    "#strip_short deletes words smaller 3\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(strip_short)\n",
    " \n",
    "#strip links\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')\n",
    "\n",
    "# Create a list of stop words to remove \n",
    "stop_words_to_remove = ['nicht', 'nichts']\n",
    "\n",
    "stop_words_to_add = ['vor', 'in', 'den', 'dem', 'beim', 'wir', 'der', 'ist','ende', 'seite', 'ersten', 'fürs', 'eh', 'blick', 'schon', 'zumal', 'erst', 'mal', 'bild', 't', '(dpa)']\n",
    "\n",
    "# Remove the stop words to remove from the stop words list\n",
    "for word in stop_words_to_remove:\n",
    "  german_stop_words.remove(word)\n",
    "\n",
    "german_stop_words.append(stop_words_to_add)\n",
    "\n",
    "# Define a function to apply remove_stopwords on a column\n",
    "def remove_stopwords_from_text(text):\n",
    "    return remove_stopwords(text, stopwords=german_stop_words)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'text' column using the apply method\n",
    "data_rm_1['data'] = data_rm_1['data'].apply(remove_stopwords_from_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm_1.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainer xabi alonso mitgereisten fans monacomit familie genoss xabi alonso team hotel monaco moment erfolges dramatischen einzug achtelfinale europa league ,,aber gab zeit feiern\" sagte trainer bayer leverkusen personlich wohl wichtigste spiel jungen trainerlaufbahn erlebt alonso ,,es intensiv fur ersten mal situation ruhig fokussiert besten entscheidungen treffen bessere emotionale kontrolle besser spiel leider konnten nicht verteidigen zufrieden leistung mannschaft \"wie gross anspannung elfmeterschiessen alonso ,,ehrlich vertrauen mittwoch training elfmeter geubt gut azmoun gut amiri gut schon klare idee spieler schiessen konnte bundesliga viele elfer verschossen funfmal folge getroffen effektiv ende passieren spieler gut gemacht gibt trick lotto gestern glucklichen \"glucksmoment exequiel palacios hebt tor abnach euro highlight geht bundesliga sonntag uhr beim freiburg ,,wir kennen freiburg gerade guten moment spielen hohen intensitat ahnlich mainz vielleicht spiel mainz gute schule fur fur freiburg spiel\" sagt alonso bayer tross bleibt tag monaco samstag uhr fliegt team basel trainiert anschliessend freiburg wegen leverkusens strafstoss krise freche elfer aktion mainz torwart alonso ,,nach minuten vielen emotionen brauchen frische beine fur freiburg sehen spieler besten erholt stunde fur erholung wichtig periode brauchen ganze mannschaft ganzen kader brauchen spieler sonntag sicher wechseln \"personell klar verteidiger jonathan tah piero hincapie gelb gesperrt amine adli wegen rot sperre zuschauen europa league nicht gemeldete daley sinkgraven oberschenkel probleme uberwunden ,,er spielen\" erklart alonso moussa diaby besteht adduktoren problemen hoffnung kraft fur startelf reicht alonso ,,wir mussten monaco vorsichtig sehen wunsch immer spielen mussen sagen bleib\\' ruhig brauchen moussa besten form \"leverkusen siegt europa league dramatisch elferschiessen monaco bayer leverkusen gibt interessante massnahme fur auslandischen profis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rm_1['data'].iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm_1.to_csv('/Users/kevingiesen/Library/Mobile Documents/com~apple~CloudDocs/BIPM Master/Semester 2/TWSM/TWSM Project/SS23-BIPM-Analytics-Lab---Group-4-repository/Preprocessing/data_clean/de_clean_1.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Transformation (setence with Playernames)\n",
    "The second transformation focus on the deletion of sentences to clean the corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lines and following lines where the Player name appears in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete content pattern\n",
    "df['data'] = df['data'].apply(lambda x: re.sub(r\"^{\\'content\\': \\'\", \"\", str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into lower case\n",
    "data_lower = df.copy()\n",
    "\n",
    "data_lower['data'] = data_lower['data'].str.lower()\n",
    "data_lower['player'] = data_lower['player'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_playernames = find_lines_with_player(data_lower, data_lower['player'].unique(), n_lines = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_playernames['data'] = data_with_playernames['data'].apply(lambda x: re.sub(r'[^\\w\\s]', lambda match: map_emoji_to_description(match.group(), language = 'de',), str(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm_2 = data_with_playernames.copy()\n",
    "\n",
    "# strip_numeric -> removing digits (https://gensimr.news-r.org/reference/strip_numeric.html)\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(strip_numeric)\n",
    "\n",
    "# strip_punctutation -> removing punctations (https://gensimr.news-r.org/reference/strip_punctuation.html)\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(strip_punctuation)\n",
    "\n",
    "# strip multiple whitespaces also \\n -> (https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.strip_multiple_whitespaces)\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(strip_multiple_whitespaces)\n",
    "\n",
    "#strip spanish accents\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(lambda x: remove_accents(str(x)))\n",
    "\n",
    "#strip_short deletes words smaller 3\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(strip_short)\n",
    " \n",
    "#strip links\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stopwords function to the 'text' column using the apply method\n",
    "data_rm_2['data'] = data_rm_2['data'].apply(remove_stopwords_from_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nutze kicker digitalen plattformen gewohnt werbung tracking zustimmung jederzeit fur zukunft widerrufen details werbe analyse trackern findest unserer datenschutzerklarung cookies tracking ende seite bayer donnerstag achtelfinal hinspiel europa league ferencvaros budapest empfangt robert andrich fehlen exequiel palacios sah defensive mittelfeldspieler beim erfolg elfmeterschiessen monaco dritte gelbe karte gesperrt massive schwachung fur werkself doppelsechs andrich palacios zuletzt erfolgsfaktor andrich ausgerechnet ersten kurzen phase saison bayer gleichzeitig spielerisch uberzeugt erfolgreichen fussball spielt zwangspause einlegen wurmt bedingt schon argerlich irgendwann ware sperre wahrscheinlich gekommen daher lieber eventuell viertel halbfinale sorgen erklart jahrige lacheln'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rm_2['data'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm_2.to_csv('/Users/kevingiesen/Library/Mobile Documents/com~apple~CloudDocs/BIPM Master/Semester 2/TWSM/TWSM Project/SS23-BIPM-Analytics-Lab---Group-4-repository/Preprocessing/data_clean/de_clean_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
