{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Bert Multilingual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook aims to process data that has been previously cleaned and provide a specific score for sentiment analysis. Once this score is generated, an accuracy analysis will be performed to check the performance of the applied model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_numeric, strip_punctuation, strip_multiple_whitespaces, strip_short\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used is bert-base-multilingual-uncased-sentiment from the hugging face library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "\n",
    "# Creating the tokenizer for sentiment analysis using the specified pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# Creating the model for sequence classification using the specified pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is load, previously cleaned in the preprocessing models. The csv that will be used is data_clean_1. This is a data set cleaned, which only contains the sentence where the player name is. It also contains 30 rows per language which has been manually labeled, to enable later accuracy performance report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection of this specific dataset was based on two main factors. Firstly, it aligned with the specifications and examples that the BERT-multilingual model was designed to work with. Secondly, after testing various other cleaned datasets, this particular one demonstrated better accuracy and more reliable results. Some of the other datasets were yielding all positive or all negative results, making this dataset the preferred choice for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_de = pd.read_csv('../Preprocessing/data_clean/labeled-data/labeled-de_clean_1-1.csv',sep = ';')\n",
    "#df_en = pd.read_csv('../Preprocessing/data_clean/en_clean_1.csv')\n",
    "df_en = pd.read_csv('../Preprocessing/data_clean/labeled-data/labeled-en_clean_1-1_not101010.csv')\n",
    "#df_es = pd.read_csv('../Preprocessing/data_clean/en_clean_1.csv')\n",
    "df_es = pd.read_csv('../Preprocessing/data_clean/labeled-data/labeled-es_clean_1-1.csv', sep = ';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the punctuation that was still there due to their need for extracting the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip punctuation\n",
    "df_de['data'] = df_de['data'].apply(strip_punctuation)\n",
    "df_en['data'] = df_en['data'].apply(strip_punctuation)\n",
    "df_es['data'] = df_es['data'].apply(strip_punctuation)\n",
    "\n",
    "# Strip white spaces\n",
    "df_de['data'] = df_de['data'].apply(strip_multiple_whitespaces)\n",
    "df_en['data'] = df_en['data'].apply(strip_multiple_whitespaces)\n",
    "df_es['data'] = df_es['data'].apply(strip_multiple_whitespaces)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple function that allows the model to operate for each record in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of function to assign a sentiment score for each record of the df\n",
    "def sentiment_score(data):\n",
    "    if isinstance(data, str):\n",
    "        tokens = tokenizer.encode(data, return_tensors='pt')\n",
    "        result = model(tokens)\n",
    "        return int(torch.argmax(result.logits)) + 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing the funtion sentiment_score for each data set per language\n",
    "df_de['sentiment'] = df_de['data'].apply(lambda x: sentiment_score(x[:512]))\n",
    "df_en['sentiment'] = df_en['data'].apply(lambda x: sentiment_score(x[:512]))\n",
    "df_es['sentiment'] = df_es['data'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate scores to positive, neutral and negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the results with the manually labled records, the following translation into positive, neutral and negative are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for distribution\n",
    "sentiment_mapping = {1: 'negativ', 2: 'neutral', 3: 'neutral', 4: 'neutral', 5: 'positiv'}\n",
    "\n",
    "# Replace the numbers with labels using the mapping\n",
    "df_de['sentiment_label'] = df_de['sentiment'].map(sentiment_mapping)\n",
    "df_en['sentiment_label'] = df_en['sentiment'].map(sentiment_mapping)\n",
    "df_es['sentiment_label'] = df_es['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all sentiment scores have been added, the data needs to be stored for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes vertically\n",
    "merged_df = pd.concat([df_de, df_en, df_es], ignore_index=True)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'data_sentiment_final.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "merged_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the manually labeled rows an accuracy performance analysis is needed. The base for this analysis is the confusion matrix. The perofrmance per language per category, taking into acount f1, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_de.dropna(subset=['Label'], inplace=True)\n",
    "df_en.dropna(subset=['Label'], inplace=True)\n",
    "df_es.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for exact match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy measure captures the exact match, indicating that the manually given label exactly matches the predicted-mapped label. In other words, it evaluates how many predicted labels are precisely the same as the ground-truth (manually assigned) labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DE: 56.67%\n",
      "Accuracy EN: 46.67%\n",
      "Accuracy ES: 43.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy_de = (df_de['sentiment_label'] == df_de['Label']).mean() * 100\n",
    "accuracy_en = (df_en['sentiment_label'] == df_en['Label']).mean() * 100\n",
    "accuracy_es = (df_es['sentiment_label'] == df_es['Label']).mean() * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy DE: {:.2f}%\".format(accuracy_de))\n",
    "print(\"Accuracy EN: {:.2f}%\".format(accuracy_en))\n",
    "print(\"Accuracy ES: {:.2f}%\".format(accuracy_es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.56      0.50      0.53        10\n",
      "     neutral       0.53      0.80      0.64        10\n",
      "     positiv       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.59      0.57      0.56        30\n",
      "weighted avg       0.59      0.57      0.56        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting the actual sentiment labels\n",
    "actual_labels = df_de['Label']\n",
    "\n",
    "# Extracting the predicted sentiment labels\n",
    "predicted_labels = df_de['sentiment_label']\n",
    "\n",
    "# Calculating the classification report based on the actual and predicted sentiment labels\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "\n",
    "# Displaying the classification report which includes precision, recall, F1-score\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.31      1.00      0.47         4\n",
      "     neutral       0.62      0.62      0.62        13\n",
      "     positiv       0.50      0.15      0.24        13\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.47      0.59      0.44        30\n",
      "weighted avg       0.52      0.47      0.43        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting the actual sentiment labels\n",
    "actual_labels = df_en['Label']\n",
    "\n",
    "# Extracting the predicted sentiment labels\n",
    "predicted_labels = df_en['sentiment_label']\n",
    "\n",
    "# Calculating the classification report based on the actual and predicted sentiment labels\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "\n",
    "# Displaying the classification report which includes precision, recall, F1-score\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.42      0.50      0.45        10\n",
      "     neutral       0.44      0.80      0.57        10\n",
      "     positiv       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.29      0.43      0.34        30\n",
      "weighted avg       0.29      0.43      0.34        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galachaparro/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/galachaparro/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/galachaparro/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extracting the actual sentiment labels\n",
    "actual_labels = df_es['Label']\n",
    "\n",
    "# Extracting the predicted sentiment labels\n",
    "predicted_labels = df_es['sentiment_label']\n",
    "\n",
    "# Calculating the classification report based on the actual and predicted sentiment labels\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "\n",
    "# Displaying the classification report which includes precision, recall, F1-score\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.41      0.58      0.48        24\n",
      "     neutral       0.52      0.73      0.61        33\n",
      "     positiv       0.60      0.18      0.28        33\n",
      "\n",
      "    accuracy                           0.49        90\n",
      "   macro avg       0.51      0.50      0.46        90\n",
      "weighted avg       0.52      0.49      0.45        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the dataframes vertically\n",
    "merged_df = pd.concat([df_de, df_en, df_es], ignore_index=True)\n",
    "\n",
    "# Extracting the actual sentiment labels\n",
    "actual_labels = merged_df['Label']\n",
    "\n",
    "# Extracting the predicted sentiment labels\n",
    "predicted_labels = merged_df['sentiment_label']\n",
    "\n",
    "# Calculating the classification report based on the actual and predicted sentiment labels\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "\n",
    "# Displaying the classification report which includes precision, recall, F1-score\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a CSV file that will contain the sentiment score and label predicted by the model for each row of data. Simultaneously, this provides us with information on the accuracy of the model for each language and overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in understanding why we did not choose to use the data set \"data_condensed,\" we have further developments and explanations after this notebook summary. These additional details provide insights into the decision-making process and the reasons behind the choices made regarding the data selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps for Buyer04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next steps for Buyer04, we would recommend exploring other models that are specifically designed for accurate analysis in the context of sports news. Different models might offer better performance and results for sentiment analysis in this domain. \n",
    "\n",
    "Fine-tuning a sentiment model should also be tried out. \n",
    "\n",
    "Another approach to improve accuracy is to find the most suitable way to map the sentiment scores into the labels positive, negative, and neutral. Fine-tuning this mapping process based on the specific characteristics of sports news data may lead to more precise sentiment predictions and better overall performance of the sentiment analysis system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data condensed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data_condensed to check performance of bert-multilingual model assigning sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data condensed\n",
    "df_de_con = pd.read_csv('https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/Preprocessing/data_clean/de_clean_condensed.csv')\n",
    "df_en_con = pd.read_csv('https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/Preprocessing/data_clean/en_clean_condensed_punc_play.csv')\n",
    "df_es_con = pd.read_csv('https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/Preprocessing/data_clean/es_clean_condensed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sentiment analysis bert-multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing the funtion sentiment_score for each data set per language\n",
    "df_de_con['sentiment'] = df_de_con['data'].apply(lambda x: sentiment_score(x[:512]))\n",
    "df_en_con['sentiment'] = df_en_con['data'].apply(lambda x: sentiment_score(x[:512]))\n",
    "df_es_con['sentiment'] = df_es_con['data'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy report cannot be generated for \"data_clean_1-1\" since manual labeling was not performed. However, we are evaluating the sentiment scores given by the model by grouping them based on the mean per player. Subsequently, we plot the results to observe the distribution and representation of scores per player. This analysis allows us to gain insights into the sentiment tendencies for different players in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results indicate a very low sentiment tendency among all the players and languages, especially for the Spanish data. This is in contrast to what we typically read in the news, where the perceived sentiment in Spanish is mostly positive. The observed discrepancy between the sentiment scores from the model and the expected sentiment based on news reports is noteworthy and requires further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score per player DE\n",
      "player\n",
      "exequiel palacios    1.833333\n",
      "jeremie frimpong     1.939130\n",
      "jonathan tah         2.223529\n",
      "mitchel bakker       2.000000\n",
      "moussa diaby         2.058824\n",
      "mykhaylo mudryk      1.111111\n",
      "piero hincapie       1.646341\n",
      "Name: sentiment, dtype: float64\n",
      "Sentiment score per player EN\n",
      "player\n",
      "exequiel palacios    1.814815\n",
      "jeremie frimpong     2.041667\n",
      "jonathan tah         2.000000\n",
      "mitchel bakker       2.909091\n",
      "moussa diaby         1.815603\n",
      "mykhaylo mudryk      1.777778\n",
      "piero hincapie       1.857143\n",
      "Name: sentiment, dtype: float64\n",
      "Sentiment score per player ES\n",
      "player\n",
      "exequiel palacios    1.422680\n",
      "jeremie frimpong     1.869565\n",
      "jonathan tah         1.666667\n",
      "mitchel bakker       1.545455\n",
      "moussa diaby         1.193548\n",
      "mykhaylo mudryk      1.148148\n",
      "piero hincapie       1.800000\n",
      "piero hincapi√©       1.698630\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Grouping the data by 'player' and calculating the mean of 'sentiment' for each player\n",
    "mean_sentiment_de_con = df_de_con.groupby('player')['sentiment'].mean()\n",
    "mean_sentiment_en_con = df_en_con.groupby('player')['sentiment'].mean()\n",
    "mean_sentiment_es_con = df_es_con.groupby('player')['sentiment'].mean()\n",
    "\n",
    "print('Sentiment score per player DE')\n",
    "print(mean_sentiment_de_con)\n",
    "print('Sentiment score per player EN')\n",
    "print(mean_sentiment_en_con)\n",
    "print('Sentiment score per player ES')\n",
    "print(mean_sentiment_es_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment score distribution per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the count of each sentiment category for each DataFrame\n",
    "es_sentiment_counts_con = df_es_con['sentiment'].value_counts().sort_index()\n",
    "de_sentiment_counts_con = df_de_con['sentiment'].value_counts().sort_index()\n",
    "en_sentiment_counts_con = df_en_con['sentiment'].value_counts().sort_index()\n",
    "\n",
    "# Set the x-axis labels\n",
    "sentiment_labels = ['1', '2', '3', '4', '5']\n",
    "x = np.arange(len(sentiment_labels))\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.2\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the counts for each sentiment category for each DataFrame\n",
    "ax.bar(x - bar_width, es_sentiment_counts_con, width=bar_width, label='spanish')\n",
    "ax.bar(x, de_sentiment_counts_con, width=bar_width, label='german')\n",
    "ax.bar(x + bar_width, en_sentiment_counts_con, width=bar_width, label='english')\n",
    "\n",
    "# Set the x-axis ticks and labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sentiment_labels)\n",
    "\n",
    "# Set the plot title and labels\n",
    "ax.set_title('Sentiment Counts for Each Language')\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, we review the score distribution across the different languages. It is evident that the dataset, regardless of the language, is mostly labeled as having a negative sentiment with a score of 1. This contradicts what we typically read in the news, as all the languages do not reflect such a negative sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
