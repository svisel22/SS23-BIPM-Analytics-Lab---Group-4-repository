{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Spanish Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, specifically for the Spanish data, we will apply a series of techniques to remove ads, noise, and any information that is not needed for our analysis. We will clean the data that has been previously extracted and store it in different files and structures to fulfill the requirements of the models that will be applied later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "from utils import remove_similar_rows, find_lines_with_player, remove_similar_rows_per_player, map_emoji_to_description, del_patterns, extract_sentence, name_wordgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_numeric, strip_punctuation, strip_multiple_whitespaces, strip_short\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data from our csv file with all the previously pulled data. And we filter Spanish language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../data_files/all_data_v3.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': \"DIRECTO\\nMercado de fichajes de f...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-29T18:25:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'Con el primer mes del 2023 a poco...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-30T16:52:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'Deportes\\nGustavo Puerta ya no ju...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-31T20:41:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'Dólar blue\\nAlberto Fernández\\nMa...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-09T18:32:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'Dólar blue\\nAlberto Fernández\\nMa...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-12T21:13:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>{'content': \"Juventus rescató un empate 1-1 fr...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T19:05:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>{'content': \"Juventus rescató un empate 1-1 fr...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T18:26:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>{'content': 'Este jueves se abren las series d...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T13:44:18Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>{'content': 'Con 10 futbolistas argentinos, la...</td>\n",
       "      <td>Exequiel Palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-10T16:03:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>{'content': \"Mudryk, con la camiseta del Chels...</td>\n",
       "      <td>Mykhaylo Mudryk</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-25T10:35:41Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data             player  \\\n",
       "0    {'content': \"DIRECTO\\nMercado de fichajes de f...  Exequiel Palacios   \n",
       "1    {'content': 'Con el primer mes del 2023 a poco...  Exequiel Palacios   \n",
       "2    {'content': 'Deportes\\nGustavo Puerta ya no ju...  Exequiel Palacios   \n",
       "3    {'content': 'Dólar blue\\nAlberto Fernández\\nMa...  Exequiel Palacios   \n",
       "4    {'content': 'Dólar blue\\nAlberto Fernández\\nMa...  Exequiel Palacios   \n",
       "..                                                 ...                ...   \n",
       "270  {'content': \"Juventus rescató un empate 1-1 fr...  Exequiel Palacios   \n",
       "271  {'content': \"Juventus rescató un empate 1-1 fr...  Exequiel Palacios   \n",
       "272  {'content': 'Este jueves se abren las series d...  Exequiel Palacios   \n",
       "273  {'content': 'Con 10 futbolistas argentinos, la...  Exequiel Palacios   \n",
       "274  {'content': \"Mudryk, con la camiseta del Chels...    Mykhaylo Mudryk   \n",
       "\n",
       "    language           publishedAt  \n",
       "0         es  2023-01-29T18:25:03Z  \n",
       "1         es  2023-01-30T16:52:46Z  \n",
       "2         es  2023-01-31T20:41:38Z  \n",
       "3         es  2023-02-09T18:32:38Z  \n",
       "4         es  2023-02-12T21:13:55Z  \n",
       "..       ...                   ...  \n",
       "270       es  2023-05-11T19:05:33Z  \n",
       "271       es  2023-05-11T18:26:06Z  \n",
       "272       es  2023-05-11T13:44:18Z  \n",
       "273       es  2023-05-10T16:03:25Z  \n",
       "274       es  2023-05-25T10:35:41Z  \n",
       "\n",
       "[275 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out the Spanish data and reindex\n",
    "df_es = df[df[\"language\"] == \"es\"]\n",
    "\n",
    "#Reset index\n",
    "df_es = df_es.reset_index(drop=True)\n",
    "df_es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove similiar rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a pre-tailored function to remove duplicates and rows that were mistakenly stored twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the similiar rows (The Function is imported from utils on top)\n",
    "df_es = remove_similar_rows_per_player(df_es, df_es['player'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data into lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform data and player into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': \"directo\\nmercado de fichajes de f...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-29T18:25:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'con el primer mes del 2023 a poco...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-30T16:52:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'deportes\\ngustavo puerta ya no ju...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-31T20:41:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'dólar blue\\nalberto fernández\\nma...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-09T18:32:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'dólar blue\\nalberto fernández\\nma...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-12T21:13:55Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data             player  \\\n",
       "0  {'content': \"directo\\nmercado de fichajes de f...  exequiel palacios   \n",
       "1  {'content': 'con el primer mes del 2023 a poco...  exequiel palacios   \n",
       "2  {'content': 'deportes\\ngustavo puerta ya no ju...  exequiel palacios   \n",
       "3  {'content': 'dólar blue\\nalberto fernández\\nma...  exequiel palacios   \n",
       "4  {'content': 'dólar blue\\nalberto fernández\\nma...  exequiel palacios   \n",
       "\n",
       "  language           publishedAt  \n",
       "0       es  2023-01-29T18:25:03Z  \n",
       "1       es  2023-01-30T16:52:46Z  \n",
       "2       es  2023-01-31T20:41:38Z  \n",
       "3       es  2023-02-09T18:32:38Z  \n",
       "4       es  2023-02-12T21:13:55Z  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy\n",
    "data_lower_es = df_es.copy()\n",
    "\n",
    "# Transform data into lower case\n",
    "data_lower_es['data'] = data_lower_es['data'].str.lower()\n",
    "data_lower_es['player'] = data_lower_es['player'].str.lower()\n",
    "data_lower_es.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large number of noice and irrelevant information, patterns are defined to be removed from all texts. These patterns are specific for Spanish texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patterns to delete\n",
    "patternlist = [\n",
    "    'content',\n",
    "    'directo',\n",
    "    'espacio publicitario',\n",
    "    'copyright',\n",
    "    'foto:',\n",
    "    'todos los derechos reservados',\n",
    "    'derechos reservados',\n",
    "    'suscribete',\n",
    "    'queda prohibida la reproducción',\n",
    "    'parcial, por',\n",
    "    'cualquier medio, de todos los contenidos sin autorización expresa de grupo el comercio',\n",
    "    'pic.twitter.com'\n",
    "   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_wo_pattern = data_lower_es.copy()\n",
    "\n",
    "# Delete patterns\n",
    "data_wo_pattern['data'] = data_wo_pattern['data'].apply(lambda x: del_patterns(str(x), patternlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '\\\\xaO' with a whitespace in the 'data' column\n",
    "data_wo_pattern['data'] = data_wo_pattern['data'].str.replace(r'\\\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Emojis to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the presence of emojis, they are being translated into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_wo_emojis = data_wo_pattern.copy()\n",
    "\n",
    "# Use map_emoji_to_description to translate emojis into text\n",
    "data_wo_emojis['data'] = data_wo_emojis['data'].apply(lambda x: re.sub(r'[^\\w\\s]', lambda match: map_emoji_to_description(match.group(), language = 'es',), str(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Noise\" refers to non-meaningful data, such as numbers, links, additional whitespaces, and for Spanish data, it also includes accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_rm_es = data_wo_emojis.copy()\n",
    "\n",
    "# Strip_numeric\n",
    "data_rm_es['data'] = data_rm_es['data'].apply(strip_numeric)\n",
    "\n",
    "# Strip links\n",
    "data_rm_es['data'] = data_rm_es['data'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))\n",
    "\n",
    "# Strip multiple whitespaces also \\n\n",
    "data_rm_es['data'] = data_rm_es['data'].apply(strip_multiple_whitespaces)\n",
    "\n",
    "# Create remove accents function\n",
    "def remove_accents(text):\n",
    "    return unidecode(text)\n",
    "\n",
    "# Strip spanish accents\n",
    "data_rm_es['data'] = data_rm_es['data'].apply(lambda x: remove_accents(str(x)))\n",
    "data_rm_es['player'] = data_rm_es['player'].apply(lambda x: remove_accents(str(x)))\n",
    "\n",
    "# Create a copy\n",
    "data_es_clean1 = data_rm_es.copy()\n",
    "\n",
    "# Reset index\n",
    "data_es_clean1.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data clean 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is stored for a later treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data \n",
    "#data_es_clean1.to_csv('../data_files/data_clean/es_clean_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess for data clean 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_wo_short = data_es_clean1.copy()\n",
    "\n",
    "# Remove short words\n",
    "data_wo_short['data'] = data_wo_short['data'].apply(strip_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create copy to new df data_rm_sw as in data removed stopwords\n",
    "data_es_sw = data_wo_short.copy()\n",
    "\n",
    "#Load stopwords\n",
    "#nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stop words to remove \n",
    "stop_words_to_remove = ['ni', 'no', 'sin']\n",
    "\n",
    "# Remove the stop words to remove from the stop words list\n",
    "for word in stop_words_to_remove:\n",
    "  spanish_stopwords.remove(word)\n",
    "\n",
    "# Define a function to apply remove_stopwords on a column\n",
    "def remove_stopwords_from_text(text):\n",
    "    return remove_stopwords(text, stopwords=spanish_stopwords)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'text' column using the apply method\n",
    "data_es_sw['data'] = data_es_sw['data'].apply(remove_stopwords_from_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy for data clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to store the cleaning process so far because the next process needs puntuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_es_clean3 = data_es_sw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_wo_pun = data_es_sw.copy()\n",
    "\n",
    "# Remove punctuation\n",
    "data_wo_pun['data'] = data_wo_pun['data'].apply(strip_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data clean 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_es_clean2 = data_wo_pun.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data \n",
    "#data_es_clean2.to_csv('../data_files/data_clean/es_clean_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data condensed\n",
    "The third transformation focus on the deletion of sentences to clean the corpus. The only paragraphs kept are the one including the player names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get lines and following lines where the Player name appears in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_es_pp = data_es_clean3.copy()\n",
    "\n",
    "# Select only paragraphs which include playernames \n",
    "data_es_pp = find_lines_with_player(data_es_pp, data_es_pp['player'].unique(), n_lines = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adeyemi firmo primer gol bundesliga javier alf...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-29T18:25:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ultima semana marzo primera ventana partidos i...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-30T16:52:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gustavo puerta jugara bayer leverkusen enterat...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-31T20:41:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alberto fernandez mauricio macri indec harvard...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-09T18:32:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberto fernandez mauricio macri indec harvard...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-12T21:13:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>minuto, visitante habia llegado arco romano ge...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T21:13:48Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>bayer leverkusen jugo visita roma, partido ida...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T20:56:21Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ecuatoriano volvera semifinales torneo uefa, a...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-11T18:30:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>seleccion ecuador jugara dos ultimos amistosos...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-10T23:37:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>auspiciado agenda semana 'quien juega hoy' dir...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-05-09T00:58:48Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data             player  \\\n",
       "0   adeyemi firmo primer gol bundesliga javier alf...  exequiel palacios   \n",
       "1   ultima semana marzo primera ventana partidos i...  exequiel palacios   \n",
       "2   gustavo puerta jugara bayer leverkusen enterat...  exequiel palacios   \n",
       "3   alberto fernandez mauricio macri indec harvard...  exequiel palacios   \n",
       "4   alberto fernandez mauricio macri indec harvard...  exequiel palacios   \n",
       "..                                                ...                ...   \n",
       "73  minuto, visitante habia llegado arco romano ge...     piero hincapie   \n",
       "74  bayer leverkusen jugo visita roma, partido ida...     piero hincapie   \n",
       "75  ecuatoriano volvera semifinales torneo uefa, a...     piero hincapie   \n",
       "76  seleccion ecuador jugara dos ultimos amistosos...     piero hincapie   \n",
       "77  auspiciado agenda semana 'quien juega hoy' dir...     piero hincapie   \n",
       "\n",
       "   language           publishedAt  \n",
       "0        es  2023-01-29T18:25:03Z  \n",
       "1        es  2023-01-30T16:52:46Z  \n",
       "2        es  2023-01-31T20:41:38Z  \n",
       "3        es  2023-02-09T18:32:38Z  \n",
       "4        es  2023-02-12T21:13:55Z  \n",
       "..      ...                   ...  \n",
       "73       es  2023-05-11T21:13:48Z  \n",
       "74       es  2023-05-11T20:56:21Z  \n",
       "75       es  2023-05-11T18:30:25Z  \n",
       "76       es  2023-05-10T23:37:55Z  \n",
       "77       es  2023-05-09T00:58:48Z  \n",
       "\n",
       "[273 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that are empty\n",
    "data_es_er = data_es_pp.replace('', pd.NA)\n",
    "data_es_er.dropna(inplace=True)\n",
    "data_es_er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete playernames from their sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the playernames took a huge influence on the clustering they will be removed for each player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_es_pn = data_es_er.copy()\n",
    "\n",
    "# For every player remove their names from the texts \n",
    "for player in data_es_pn['player'].unique():\n",
    "    f_l_name = player.split()\n",
    "\n",
    "    # Extracting the first name\n",
    "    first_name = str(f_l_name[0])\n",
    "\n",
    "    # Extracting the last name\n",
    "    last_name = str(f_l_name[1])\n",
    "\n",
    "    updated_pattern = r\"\\b(\" + first_name.lower() + r\"|\" + last_name.lower() + r\")\\b|\"\n",
    "\n",
    "\n",
    "    # Apply the function to the data column\n",
    "    data_es_pn.loc[data_es_pn['player'] == player, 'data'] = data_es_pn.loc[data_es_pn['player'] == player, 'data'].apply(lambda x: re.sub(updated_pattern, \"\", str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pustuation\n",
    "data_es_pn['data'] = data_es_pn['data'].apply(strip_punctuation)\n",
    "\n",
    "# Remove excesive white space\n",
    "data_es_pn['data'] = data_es_pn['data'].apply(strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data condensed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "data_es_condense = data_es_pn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data \n",
    "#data_es_condense.to_csv('../data_files/data_clean/es_clean_condensed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Sentiment Preprocessing\n",
    "For the sentiment analysis we created one additional dataset where we take just the sentence where a playername appears of the clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean dataset\n",
    "df_es_sentence = pd.read_csv('../data_files/data_clean/es_clean_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep paragraph where the player name is found\n",
    "df_es_sentence = find_lines_with_player(df_es_sentence, df_es_sentence['player'].unique(),n_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentence\n",
    "df_es_sentence = extract_sentence(df_es_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy sentence column into data and remove sentence\n",
    "df_es_sentence['data']= df_es_sentence['sentence']\n",
    "df_es_sentence.drop('sentence', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove similiar sentences \n",
    "df_es_sentence = remove_similar_rows_per_player(df_es_sentence, df_es_sentence['player'].unique())\n",
    "\n",
    "# apply wordgroups\n",
    "df_es_sentence = name_wordgroups(df_es_sentence)\n",
    "\n",
    "# delete empty rows\n",
    "df_es_sentence = df_es_sentence.replace('', pd.NA)\n",
    "df_es_sentence.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data \n",
    "#df_es_sentence.to_csv('../data_files/data_clean/es_clean_1_sen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create the following CSV files:\n",
    "\n",
    "1. data1\n",
    "2. data2\n",
    "3. data_condensed\n",
    "4. es_clean_1_sen\n",
    "\n",
    "The objective of these files is to have the data cleaned and saved at different levels of detail. They allow us to use the same data for different processes with various requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps for Bayer04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve the data processing, we could recommend Bayer04 to try different preprocessing combinations. By storing the data and experimenting with various combinations in subsequent processes, the goal is to achieve the best accuracy for each of the models. This iterative approach allows for fine-tuning the preprocessing steps and selecting the most effective ones that lead to improved model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
