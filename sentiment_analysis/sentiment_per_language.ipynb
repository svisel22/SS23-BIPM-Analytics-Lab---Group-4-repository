{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More sentiment models and their accuracy per language\n",
    "\n",
    "## Intro\n",
    "This document is used to explore diffrent sentiment models which were trained specifically for sentiment per language and evaluate their performance in order to find the most accurate model compared to the multilingual model. \n",
    "As for the multilingual model, here we also use the data clean 1 with the sentence extracted. And for english we compare the accuracy of the datasets with the extracted sentences from data clean 1 and data condensed to determine whether less data is better for the model. This was only done for the english data condensed, because of time limitations that didn't allow further data labeling.\n",
    "\n",
    "The examined models are:\n",
    "* German: oliverguhr/german-sentiment-bert\n",
    "* English: bert-base-uncased and VADER\n",
    "* Spanish: beto-sentiment-analysis and bert-base-spanish-wwm-uncased\n",
    "\n",
    "For the english and spanish models we use the pipeline function from the transformers library, as it includes the tokenization and the sentiment model within one step, which makes it easy to use.\n",
    "\n",
    "The performances of the models are evaluated using the function evaluate_performance that returns the accuracy, the unique predicted labels, the confusion matrix and the classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\joana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_multiple_whitespaces\n",
    "\n",
    "# Models:\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification # for german\n",
    "from pattern.en import sentiment # for english\n",
    "import nltk # for english\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # for english\n",
    "nltk.download('vader_lexicon') # for english\n",
    "from pysentimiento import create_analyzer # for spanish\n",
    "\n",
    "# Accuracy\n",
    "from utils import evaluate_performance, transform_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled data: d1_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled CSV files into a DataFrame\n",
    "df_de = pd.read_csv('../data_files/data_clean/labeled-data/labeled-de_clean_1-1.csv', sep=';')\n",
    "df_en = pd.read_csv('../data_files/data_clean/labeled-data/labeled-en_clean_1-1_not101010.csv')\n",
    "df_es = pd.read_csv('../data_files/data_clean/labeled-data/labeled-es_clean_1-1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip punctuation\n",
    "df_de['data'] = df_de['data'].apply(strip_punctuation)\n",
    "df_en['data'] = df_en['data'].apply(strip_punctuation)\n",
    "df_es['data'] = df_es['data'].apply(strip_punctuation)\n",
    "\n",
    "# Strip white spaces\n",
    "df_de['data'] = df_de['data'].apply(strip_multiple_whitespaces)\n",
    "df_en['data'] = df_en['data'].apply(strip_multiple_whitespaces)\n",
    "df_es['data'] = df_es['data'].apply(strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled data: data condensed for english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled CSV file into a DataFrame\n",
    "df_en_con = pd.read_csv('../data_files/data_clean/labeled-data/labeled-en_clean_con_sen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data condensed is already stripped of punctuation.\n",
    "\n",
    "# Strip white spaces\n",
    "df_en_con['data'] = df_en_con['data'].apply(strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German\n",
    "\n",
    "### Model: oliverguhr/german-sentiment-bert\n",
    "The model is a binary classifier on sentence level which is why the sentiment scores here are transformed in two-dimensional labels instead of three-dimensional labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trainer alonso vor den mitgereisten fans in mo...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-02-24T09:33:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zudem ist die konkurrenzsituation auf der dopp...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-03T21:35:13Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wie auch palacios sah der defensive mittelfeld...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-07T11:34:39Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>er ist eine option erklart alonso der im mitt...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-08T14:25:18Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allerdings waren in andrich und dem argentini...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-03-09T19:53:46Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data    player language  \\\n",
       "0  trainer alonso vor den mitgereisten fans in mo...  palacios       de   \n",
       "1  zudem ist die konkurrenzsituation auf der dopp...  palacios       de   \n",
       "2  wie auch palacios sah der defensive mittelfeld...  palacios       de   \n",
       "3   er ist eine option erklart alonso der im mitt...  palacios       de   \n",
       "4   allerdings waren in andrich und dem argentini...  palacios       de   \n",
       "\n",
       "            publishedAt Label sentiment  \n",
       "0  2023-02-24T09:33:31Z   NaN  negative  \n",
       "1  2023-03-03T21:35:13Z   NaN  negative  \n",
       "2  2023-03-07T11:34:39Z   NaN  negative  \n",
       "3  2023-03-08T14:25:18Z   NaN  negative  \n",
       "4  2023-03-09T19:53:46Z   NaN  negative  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Create an empty list to store the sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Iterate over the 'data' column in the DataFrame\n",
    "for text in df_de['data']:\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer.encode_plus(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform the sentiment analysis\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens)[0]\n",
    "\n",
    "    # Convert logits to predicted label (positive/negative)\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    sentiment = \"positive\" if predicted_label == 1 else \"negative\"\n",
    "\n",
    "    # Append the sentiment score to the list\n",
    "    sentiment_scores.append(sentiment)\n",
    "\n",
    "# Add the sentiment scores as a new column in the DataFrame\n",
    "df_de['sentiment'] = sentiment_scores\n",
    "\n",
    "df_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance for german bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_de.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for oliverguhr/german-sentiment-bert\n",
      "Confusion matrix: \n",
      "         negativ  positiv\n",
      "negativ       10        0\n",
      "positiv       10        0\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.50      1.00      0.67        10\n",
      "     positiv       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.25      0.50      0.33        20\n",
      "weighted avg       0.25      0.50      0.33        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for oliverguhr/german-sentiment-bert')\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_de, unique_predicted_de, confusion_matrix_de, classification_report_de = evaluate_performance(df_de, 'sentiment_bert', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_de)\n",
    "print('Classification report: ')\n",
    "print(classification_report_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English\n",
    "\n",
    "### Model 1: sentiment-analysis from bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ten if you included the toe poked volley to te...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-16T23:56:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayerleverkusen took the lead again in the st ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:50:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wissam ben yedder levelled straight away from ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:53:59Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.598611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midfielders leandro paredes juventus angel di ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:40:46Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.694157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midfielders rodrigo de paul atletico madrid le...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T18:17:37Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.694063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data    player language  \\\n",
       "0  ten if you included the toe poked volley to te...  palacios       en   \n",
       "1  bayerleverkusen took the lead again in the st ...  palacios       en   \n",
       "2  wissam ben yedder levelled straight away from ...  palacios       en   \n",
       "3  midfielders leandro paredes juventus angel di ...  palacios       en   \n",
       "4  midfielders rodrigo de paul atletico madrid le...  palacios       en   \n",
       "\n",
       "            publishedAt    Label  sentiment_bert  \n",
       "0  2023-02-16T23:56:00Z      NaN        0.514350  \n",
       "1  2023-02-23T20:50:50Z      NaN        0.624176  \n",
       "2  2023-02-23T20:53:59Z  positiv        0.598611  \n",
       "3  2023-03-03T16:40:46Z  neutral        0.694157  \n",
       "4  2023-03-03T18:17:37Z  neutral        0.694063  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate model\n",
    "sentiment_classifier_en = pipeline('sentiment-analysis', model='bert-base-uncased')\n",
    "\n",
    "# Apply sentiment analysis on the 'data' column  and store the sentiment in a new column \"sentiment_bert\"\n",
    "df_en['sentiment_bert'] = df_en['data'].apply(lambda x: sentiment_classifier_en(x)[0]['score'])\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Sentiment Intensity Analyzer from VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_bert</th>\n",
       "      <th>sentiment_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ten if you included the toe poked volley to te...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-16T23:56:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514350</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayerleverkusen took the lead again in the st ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:50:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624176</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wissam ben yedder levelled straight away from ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:53:59Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.598611</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midfielders leandro paredes juventus angel di ...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:40:46Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.694157</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midfielders rodrigo de paul atletico madrid le...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T18:17:37Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.694063</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data    player language  \\\n",
       "0  ten if you included the toe poked volley to te...  palacios       en   \n",
       "1  bayerleverkusen took the lead again in the st ...  palacios       en   \n",
       "2  wissam ben yedder levelled straight away from ...  palacios       en   \n",
       "3  midfielders leandro paredes juventus angel di ...  palacios       en   \n",
       "4  midfielders rodrigo de paul atletico madrid le...  palacios       en   \n",
       "\n",
       "            publishedAt    Label  sentiment_bert  sentiment_nltk  \n",
       "0  2023-02-16T23:56:00Z      NaN        0.514350          0.0000  \n",
       "1  2023-02-23T20:50:50Z      NaN        0.624176         -0.0516  \n",
       "2  2023-02-23T20:53:59Z  positiv        0.598611          0.2263  \n",
       "3  2023-03-03T16:40:46Z  neutral        0.694157          0.4215  \n",
       "4  2023-03-03T18:17:37Z  neutral        0.694063          0.4215  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    return sentiment_scores['compound']\n",
    "\n",
    "\n",
    "# Apply sentiment analysis to the \"data\" column and store the sentiment in a new column \"sentiment_nltk\"\n",
    "df_en['sentiment_nltk'] = df_en['data'].apply(get_sentiment)\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance for all english models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_en.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for bert-base-uncased\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        1        3\n",
      "neutral        0        5        8\n",
      "positiv        0        5        8\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00         4\n",
      "     neutral       0.45      0.38      0.42        13\n",
      "     positiv       0.42      0.62      0.50        13\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.29      0.33      0.31        30\n",
      "weighted avg       0.38      0.43      0.40        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for bert-base-uncased')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_en, 'sentiment_3_label_bert')\n",
    "df_en['sentiment_3_label_bert'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_en_bert, unique_predicted_en_bert, confusion_matrix_en_bert, classification_report_en_bert = evaluate_performance(df_en, 'sentiment_3_label_bert', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_en_bert)\n",
    "print('Classification report: ')\n",
    "print(classification_report_en_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for nltk\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        1        3\n",
      "neutral        0        5        8\n",
      "positiv        0        5        8\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00         4\n",
      "     neutral       0.45      0.38      0.42        13\n",
      "     positiv       0.42      0.62      0.50        13\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.29      0.33      0.31        30\n",
      "weighted avg       0.38      0.43      0.40        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for nltk')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_en, 'sentiment_bert')\n",
    "df_en['sentiment_3_label_bert'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_en_nltk, unique_predicted_en_nltk, confusion_matrix_en_nltk, classification_report_en_nltk = evaluate_performance(df_en, 'sentiment_3_label_bert', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_en_nltk)\n",
    "print('Classification report: ')\n",
    "print(classification_report_en_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish\n",
    "\n",
    "### Model 1: sentiment-analysis from spanish bert: beto-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier_es_beto = pipeline('sentiment-analysis', model='finiteautomata/beto-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_beto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adeyemi firmo el que es su primer gol en lo qu...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-29T18:25:03Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>el club aleman que siempre se ha caracterizado...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-31T20:41:38Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alberto fernandez el presidente de la afa clau...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-09T18:32:38Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alberto fernandez tambien participaron los otr...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-12T21:13:55Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fue el momento en que desde las tribunas se de...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-13T01:05:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data    player language  \\\n",
       "0  adeyemi firmo el que es su primer gol en lo qu...  palacios       es   \n",
       "1  el club aleman que siempre se ha caracterizado...  palacios       es   \n",
       "2  alberto fernandez el presidente de la afa clau...  palacios       es   \n",
       "3  alberto fernandez tambien participaron los otr...  palacios       es   \n",
       "4  fue el momento en que desde las tribunas se de...  palacios       es   \n",
       "\n",
       "            publishedAt Label  sentiment_beto  \n",
       "0  2023-01-29T18:25:03Z   NaN        0.430724  \n",
       "1  2023-01-31T20:41:38Z   NaN        0.989890  \n",
       "2  2023-02-09T18:32:38Z   NaN        0.979528  \n",
       "3  2023-02-12T21:13:55Z   NaN        0.977206  \n",
       "4  2023-02-13T01:05:15Z   NaN        0.995160  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply sentiment analysis on the 'data' column  and store the sentiment in a new column \"sentiment_beto\"\n",
    "df_es['sentiment_beto'] = df_es['data'].apply(lambda x: sentiment_classifier_es_beto(x)[0]['score'])\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_es.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: sentiment-analysis from another spanish bert: bert-base-spanish-wwm-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier_es_bert = pipeline('sentiment-analysis', model='dccuchile/bert-base-spanish-wwm-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_beto</th>\n",
       "      <th>sentiment_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adeyemi firmo el que es su primer gol en lo qu...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-29T18:25:03Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430724</td>\n",
       "      <td>0.553467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>el club aleman que siempre se ha caracterizado...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-01-31T20:41:38Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989890</td>\n",
       "      <td>0.504837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alberto fernandez el presidente de la afa clau...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-09T18:32:38Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979528</td>\n",
       "      <td>0.522085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alberto fernandez tambien participaron los otr...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-12T21:13:55Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.534249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fue el momento en que desde las tribunas se de...</td>\n",
       "      <td>palacios</td>\n",
       "      <td>es</td>\n",
       "      <td>2023-02-13T01:05:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995160</td>\n",
       "      <td>0.562792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data    player language  \\\n",
       "0  adeyemi firmo el que es su primer gol en lo qu...  palacios       es   \n",
       "1  el club aleman que siempre se ha caracterizado...  palacios       es   \n",
       "2  alberto fernandez el presidente de la afa clau...  palacios       es   \n",
       "3  alberto fernandez tambien participaron los otr...  palacios       es   \n",
       "4  fue el momento en que desde las tribunas se de...  palacios       es   \n",
       "\n",
       "            publishedAt Label  sentiment_beto  sentiment_bert  \n",
       "0  2023-01-29T18:25:03Z   NaN        0.430724        0.553467  \n",
       "1  2023-01-31T20:41:38Z   NaN        0.989890        0.504837  \n",
       "2  2023-02-09T18:32:38Z   NaN        0.979528        0.522085  \n",
       "3  2023-02-12T21:13:55Z   NaN        0.977206        0.534249  \n",
       "4  2023-02-13T01:05:15Z   NaN        0.995160        0.562792  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply sentiment analysis on the 'data' column  and store the sentiment in a new column \"sentiment_bert\"\n",
    "df_es['sentiment_bert'] = df_es['data'].apply(lambda x: sentiment_classifier_es_bert(x)[0]['score'])\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_es.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance for all spanish models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_es.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for beto-sentiment-analysis\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        2        8\n",
      "neutral        0        4        6\n",
      "positiv        0        5        5\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00        10\n",
      "     neutral       0.36      0.40      0.38        10\n",
      "     positiv       0.26      0.50      0.34        10\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.21      0.30      0.24        30\n",
      "weighted avg       0.21      0.30      0.24        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for beto-sentiment-analysis')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_en, 'sentiment_beto')\n",
    "df_es['sentiment_3_label_beto'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_es_beto, unique_predicted_es_beto, confusion_matrix_es_beto, classification_report_es_beto = evaluate_performance(df_es, 'sentiment_3_label_beto', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_es_beto)\n",
    "print('Classification report: ')\n",
    "print(classification_report_es_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for bert-base-spanish-wwm-uncased\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        7        3\n",
      "neutral        0        6        4\n",
      "positiv        0        9        1\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00        10\n",
      "     neutral       0.27      0.60      0.37        10\n",
      "     positiv       0.12      0.10      0.11        10\n",
      "\n",
      "    accuracy                           0.23        30\n",
      "   macro avg       0.13      0.23      0.16        30\n",
      "weighted avg       0.13      0.23      0.16        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for bert-base-spanish-wwm-uncased')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_es, 'sentiment_bert')\n",
    "df_es['sentiment_3_label_bert'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_es_bert, unique_predicted_es_bert, confusion_matrix_es_bert, classification_report_es_bert = evaluate_performance(df_es, 'sentiment_3_label_bert', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_es_bert)\n",
    "print('Classification report: ')\n",
    "print(classification_report_es_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English: data condensed\n",
    "\n",
    "### Model 1: sentiment-analysis from bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayerleverkusen took lead minute midfielder pa...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:50:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midfielders leandro paredes juventus angel mar...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:42:19Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.695331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half goal joshua kimmich canceled penalties pa...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T18:30:00Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.650257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>by reuters bayerleverkusen s palacios scored s...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T18:42:59Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bayerleverkusen s palacios scored second half ...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T19:05:09Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.652657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data             player  \\\n",
       "0  bayerleverkusen took lead minute midfielder pa...  exequiel palacios   \n",
       "1  midfielders leandro paredes juventus angel mar...  exequiel palacios   \n",
       "2  half goal joshua kimmich canceled penalties pa...  exequiel palacios   \n",
       "3  by reuters bayerleverkusen s palacios scored s...  exequiel palacios   \n",
       "4  bayerleverkusen s palacios scored second half ...  exequiel palacios   \n",
       "\n",
       "  language           publishedAt    Label  sentiment_bert  \n",
       "0       en  2023-02-23T20:50:50Z      NaN        0.620365  \n",
       "1       en  2023-03-03T16:42:19Z  neutral        0.695331  \n",
       "2       en  2023-03-19T18:30:00Z  positiv        0.650257  \n",
       "3       en  2023-03-19T18:42:59Z      NaN        0.642370  \n",
       "4       en  2023-03-19T19:05:09Z  positiv        0.652657  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model loaded above: sentiment_classifier_en = pipeline('sentiment-analysis', model='bert-base-uncased')\n",
    "\n",
    "# Apply sentiment analysis on the 'data' column  and store the sentiment in a new column \"sentiment_bert\"\n",
    "df_en_con['sentiment_bert'] = df_en_con['data'].apply(lambda x: sentiment_classifier_en(x)[0]['score'])\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_en_con.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Sentiment Intensity Analyzer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_bert</th>\n",
       "      <th>sentiment_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayerleverkusen took lead minute midfielder pa...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:50:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620365</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midfielders leandro paredes juventus angel mar...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:42:19Z</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.695331</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half goal joshua kimmich canceled penalties pa...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T18:30:00Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>by reuters bayerleverkusen s palacios scored s...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T18:42:59Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642370</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bayerleverkusen s palacios scored second half ...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T19:05:09Z</td>\n",
       "      <td>positiv</td>\n",
       "      <td>0.652657</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data             player  \\\n",
       "0  bayerleverkusen took lead minute midfielder pa...  exequiel palacios   \n",
       "1  midfielders leandro paredes juventus angel mar...  exequiel palacios   \n",
       "2  half goal joshua kimmich canceled penalties pa...  exequiel palacios   \n",
       "3  by reuters bayerleverkusen s palacios scored s...  exequiel palacios   \n",
       "4  bayerleverkusen s palacios scored second half ...  exequiel palacios   \n",
       "\n",
       "  language           publishedAt    Label  sentiment_bert  sentiment_nltk  \n",
       "0       en  2023-02-23T20:50:50Z      NaN        0.620365         -0.0516  \n",
       "1       en  2023-03-03T16:42:19Z  neutral        0.695331          0.4215  \n",
       "2       en  2023-03-19T18:30:00Z  positiv        0.650257          0.5859  \n",
       "3       en  2023-03-19T18:42:59Z      NaN        0.642370         -0.3400  \n",
       "4       en  2023-03-19T19:05:09Z  positiv        0.652657         -0.3400  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    return sentiment_scores['compound']\n",
    "\n",
    "\n",
    "# Apply sentiment analysis to the \"data\" column and store the sentiment in a new column \"sentiment_nltk\"\n",
    "df_en_con['sentiment_nltk'] = df_en_con['data'].apply(get_sentiment)\n",
    "\n",
    "# Print the updated dataframe\n",
    "df_en_con.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance for english condensed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Label' is NaN or empty\n",
    "df_en_con.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for bert-base-uncased on english condensed\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        2        1\n",
      "neutral        0        6        4\n",
      "positiv        0        1        9\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00         3\n",
      "     neutral       0.67      0.60      0.63        10\n",
      "     positiv       0.64      0.90      0.75        10\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.44      0.50      0.46        23\n",
      "weighted avg       0.57      0.65      0.60        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for bert-base-uncased on english condensed')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_en_con, 'sentiment_bert')\n",
    "df_en_con['sentiment_3_label_bert'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_en_bert, unique_predicted_en_bert, confusion_matrix_en_bert, classification_report_en_bert = evaluate_performance(df_en_con, 'sentiment_3_label_bert', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_en_bert)\n",
    "print('Classification report: ')\n",
    "print(classification_report_en_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance evaluation for nltk\n",
      "Confusion matrix: \n",
      "         negativ  neutral  positiv\n",
      "negativ        0        2        1\n",
      "neutral        0        6        4\n",
      "positiv        0        1        9\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negativ       0.00      0.00      0.00         3\n",
      "     neutral       0.67      0.60      0.63        10\n",
      "     positiv       0.64      0.90      0.75        10\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.44      0.50      0.46        23\n",
      "weighted avg       0.57      0.65      0.60        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\joana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Performance evaluation for nltk')\n",
    "\n",
    "# Transform score into three-dimensional label for Performance evaluation\n",
    "sentiment_3_labels = transform_scores(df_en_con, 'sentiment_3_label_nltk')\n",
    "df_en_con['sentiment_3_label_nltk'] = sentiment_3_labels\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy_en_nltk, unique_predicted_en_nltk, confusion_matrix_en_nltk, classification_report_en_nltk = evaluate_performance(df_en_con, 'sentiment_3_label_nltk', 'Label')\n",
    "\n",
    "# Print the evaluation results\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix_en_nltk)\n",
    "print('Classification report: ')\n",
    "print(classification_report_en_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "From the classification reports we see that the best accuracy is achieved by both models on the english data condensed with each an accuracy of 0,65. Next are the bert and nltk model on the english dataset data clean 1 each with an accuracy of 0,43 followed by the spanish beto model with an accuracy of 0,3. The least good model is the spanish bert model with an accuracy of 0,23.\n",
    "The accuracy of the german bert model is not comparable in this case because the accuracy was determined on two-dimensionable labels.\n",
    "\n",
    "# Next steps for Bayer04 Leverkusen\n",
    "As next steps Bayer04 could apply the multilingual model on data condensed with the sentence extracted. This could improve the accuracy of the sentiment model.  Further next steps are ligned out in the multilingual file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
