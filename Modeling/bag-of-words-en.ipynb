{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import sklearn\n",
    "import gensim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana\\AppData\\Local\\Temp\\ipykernel_22100\\2467272692.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_en2 = pd.read_csv(url_en2, sep=',', encoding='utf-8', error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#dataset 2 is for text clustering\n",
    "url_en2 = 'https://github.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/raw/main/Preprocessing/data_clean/en_clean_2.csv'\n",
    "df_en2 = pd.read_csv(url_en2, sep=',', encoding='utf-8', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>footballflorian wirtz goal bayer leverkusen eu...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-16T23:56:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xasoccer football europa league play second le...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:50:50Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pickworth mailonlineview commentsbayer leverku...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-02-23T20:53:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buenos aires world cup winner argentina celebr...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:40:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sign insign inthe star editionchange locationt...</td>\n",
       "      <td>exequiel palacios</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-03T16:42:19Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>australian associated pressview commentsthe so...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-28T11:24:40Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>julien laurens explains choice espn top star w...</td>\n",
       "      <td>piero hincapie</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-29T11:35:08Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>futurechelsea rumored beaten \"up dozen\" teams ...</td>\n",
       "      <td>piero hincapié</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-04-27T04:57:02Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>man city's alex robertson makes debut aiden o'...</td>\n",
       "      <td>piero hincapié</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-24T15:24:08Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>exequiel palacios scored penalties bayer lever...</td>\n",
       "      <td>piero hincapié</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-03-19T20:03:28Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data             player  \\\n",
       "0    footballflorian wirtz goal bayer leverkusen eu...  exequiel palacios   \n",
       "1    xasoccer football europa league play second le...  exequiel palacios   \n",
       "2    pickworth mailonlineview commentsbayer leverku...  exequiel palacios   \n",
       "3    buenos aires world cup winner argentina celebr...  exequiel palacios   \n",
       "4    sign insign inthe star editionchange locationt...  exequiel palacios   \n",
       "..                                                 ...                ...   \n",
       "284  australian associated pressview commentsthe so...     piero hincapie   \n",
       "285  julien laurens explains choice espn top star w...     piero hincapie   \n",
       "286  futurechelsea rumored beaten \"up dozen\" teams ...     piero hincapié   \n",
       "287  man city's alex robertson makes debut aiden o'...     piero hincapié   \n",
       "288  exequiel palacios scored penalties bayer lever...     piero hincapié   \n",
       "\n",
       "    language           publishedAt  \n",
       "0         en  2023-02-16T23:56:00Z  \n",
       "1         en  2023-02-23T20:50:50Z  \n",
       "2         en  2023-02-23T20:53:59Z  \n",
       "3         en  2023-03-03T16:40:46Z  \n",
       "4         en  2023-03-03T16:42:19Z  \n",
       "..       ...                   ...  \n",
       "284       en  2023-03-28T11:24:40Z  \n",
       "285       en  2023-03-29T11:35:08Z  \n",
       "286       en  2023-04-27T04:57:02Z  \n",
       "287       en  2023-03-24T15:24:08Z  \n",
       "288       en  2023-03-19T20:03:28Z  \n",
       "\n",
       "[289 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying sklearn tfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "'''info: by default this doesn't use a stopword list, but it does remove accents and transforms the data into lowercase'''\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(max_df=0.95, min_df=0.05)\n",
    "vec = TfidfVectorizer(max_df=0.95, min_df=0.05) #smoothing and inverse document frequency (= use_idf) enabled, to prevent zero devisions and have the real tfidf not only term frequency\n",
    "vec_term = TfidfVectorizer(max_df=0.95, min_df=0.05,use_idf=False, norm='l1') #only term frequency is disabled\n",
    "\n",
    "#it should only be performed on the column data, so we use ColumnTransformer to uapply tfidf selectively\n",
    "columns_to_remain = ['player', 'language', 'publishedat']\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', vec, df_en2['data']),\n",
    "        ('remainder', 'passthrough', columns_to_remain)  # Include the remaining columns as-is\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Estimator names conflict with constructor arguments: ['remainder']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transformed_data \u001b[39m=\u001b[39m column_transformer\u001b[39m.\u001b[39;49mfit_transform(df_en2)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\compose\\_column_transformer.py:722\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 722\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_transformers()\n\u001b[0;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\compose\\_column_transformer.py:400\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    397\u001b[0m names, transformers, _ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers)\n\u001b[0;32m    399\u001b[0m \u001b[39m# validate names\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_names(names)\n\u001b[0;32m    402\u001b[0m \u001b[39m# validate estimators\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m transformers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\metaestimators.py:87\u001b[0m, in \u001b[0;36m_BaseComposition._validate_names\u001b[1;34m(self, names)\u001b[0m\n\u001b[0;32m     85\u001b[0m invalid_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(names)\u001b[39m.\u001b[39mintersection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m invalid_names:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEstimator names conflict with constructor arguments: \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     89\u001b[0m             \u001b[39msorted\u001b[39m(invalid_names)\n\u001b[0;32m     90\u001b[0m         )\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     92\u001b[0m invalid_names \u001b[39m=\u001b[39m [name \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m names \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m name]\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m invalid_names:\n",
      "\u001b[1;31mValueError\u001b[0m: Estimator names conflict with constructor arguments: ['remainder']"
     ]
    }
   ],
   "source": [
    "transformed_data = column_transformer.fit_transform(df_en2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_count = vec_count.fit_transform(df_en2).toarray()\n",
    "tfidf = vec.fit_transform(df_en2).toarray()\n",
    "tfidf_term = vec_term.fit_transform(df_en2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countvectorizer [[1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]]\n",
      "tfidf: [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "term frequency: [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print('countvectorizer', tfidf_count)\n",
    "print('tfidf:', tfidf)\n",
    "print('term frequency:', tfidf_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>player</th>\n",
       "      <th>language</th>\n",
       "      <th>publishedat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  player  language  publishedat\n",
       "0   1.0     0.0       0.0          0.0\n",
       "1   0.0     0.0       1.0          0.0\n",
       "2   0.0     1.0       0.0          0.0\n",
       "3   0.0     0.0       0.0          1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf, columns=vec.vocabulary_.keys())\n",
    "df_tfidf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying gensims tfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance of sklearn and gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
