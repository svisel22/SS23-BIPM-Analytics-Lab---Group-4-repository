{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import regex as re\n",
    "import os\n",
    "#sys.path.append('../')\n",
    "#from utils import find_lines_with_player, name_wordgroups, remove_similar_rows_per_player\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in utils. for joana\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function which finds the lines where a players name is contained\n",
    "def find_lines_with_player(dataframe, playerlist, n_lines = 0):\n",
    "    \n",
    "    # create empty df \n",
    "    df_complete = pd.DataFrame()\n",
    "\n",
    "    # iterating over all players\n",
    "    for player in playerlist:\n",
    "\n",
    "        # get players first and last_name to include them in later sentence checks\n",
    "        player_first_name, player_last_name = player.split()\n",
    "\n",
    "        # just select player indiviual data\n",
    "        df_player = dataframe[dataframe[\"player\"] == player]\n",
    "        df_player = df_player.reset_index(drop=True)\n",
    "\n",
    "        # iterate over all data for the player\n",
    "        for i in range(len(df_player)):\n",
    "\n",
    "            # get the current record\n",
    "            current_line = df_player['data'].iloc[i]\n",
    "            # split up the records in lines\n",
    "            lines = current_line.split('\\\\n')\n",
    "            # create an empty string\n",
    "            new_string = ''\n",
    "\n",
    "            line_counter = 0\n",
    "            # iterate over all lines in the record\n",
    "            for line in lines:\n",
    "                # if the playername can be found in the line add the line to the string\n",
    "                if line.find(player) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "            \n",
    "                elif line.find(player_first_name) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "        \n",
    "                elif line.find(player_last_name) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "            \n",
    "                elif line_counter >= 0:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    line_counter = line_counter-1\n",
    "        \n",
    "            # switch the previos record against the newly created string \n",
    "            df_player['data'].iloc[i] = new_string\n",
    "\n",
    "        # add the new data to the Dataframe and return\n",
    "        df_complete = pd.concat([df_complete, df_player], axis=0)\n",
    "        \n",
    "    return df_complete\n",
    "\n",
    "def remove_similar_rows_per_player(df, playerlist, threshold=0.9):\n",
    "    '''The procedure of deleting similiar articles needs to be done by each player because if an article writes about \n",
    "    # e.g. two players we want to keep it for both of the players'''\n",
    "\n",
    "    # define empty df which will be returned in the end\n",
    "    df_complete = pd.DataFrame()\n",
    "\n",
    "    for player in playerlist:\n",
    "        \n",
    "        # create the df for the player\n",
    "        df_player = df[df[\"player\"] == player]\n",
    "        df_player = df_player.reset_index(drop=True)\n",
    "        column_as_df = pd.DataFrame(df_player['data'])\n",
    "\n",
    "\n",
    "        \n",
    "        # Compute similarity scores for each pair of rows\n",
    "        similarity_scores = {}\n",
    "        for i, row in column_as_df.iterrows():\n",
    "            for j, other_row in column_as_df.iterrows():\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                score = SequenceMatcher(None, row, other_row).ratio()\n",
    "                if score >= threshold:\n",
    "                    similarity_scores[(i, j)] = score\n",
    "        \n",
    "        # Identify rows to remove\n",
    "        rows_to_remove = []\n",
    "        for (i, j), score in similarity_scores.items():\n",
    "            if i not in rows_to_remove and j not in rows_to_remove:\n",
    "                rows_to_remove.append(j if df_player.index[i] < df_player.index[j] else i)\n",
    "        \n",
    "        # Remove rows and concatenate df\n",
    "        df_player = df_player.drop(rows_to_remove)\n",
    "        df_complete = pd.concat([df_complete, df_player], axis=0)\n",
    "\n",
    "        #return modified DataFrame\n",
    "    return df_complete\n",
    "\n",
    "def name_wordgroups(df):\n",
    "    '''\n",
    "    Function to match first and surname to just last name\n",
    "    '''\n",
    "    # create patterns which should be matched \n",
    "    # first lastname and firstname should both result in just lastname\n",
    "    pattern_match2d = np.array([[r\"\\b(mitchel bakker|mitchel)\\b\", 'bakker'], \n",
    "                                [r\"\\b(xabi alonso|xabi)\\b\", 'alonso'], \n",
    "                                [r\"\\b(exequiel palacios|exequiel)\\b\", 'palacios'],\n",
    "                                [r\"\\b(nadiem amiri|nadiem)\\b\", 'amiri'],\n",
    "                                [r\"\\b(kerem demirbay|kerem)\\b\", 'demirbay'],\n",
    "                                [r\"\\b(robert andrich|robert)\\b\", 'andrich'],\n",
    "                                [r\"\\b(exequiel palacios|exequiel)\\b\", 'palacios'],\n",
    "                                [r\"\\b(piero hincapie|piero)\\b\", 'hincapie'],\n",
    "                                [r\"\\b(jeremie frimpong|jeremie)\\b\", 'frimpong'],\n",
    "                                [r\"\\b(jonathan tah|jonathan)\\b\", 'tah'],\n",
    "                                [r\"\\b(moussa diaby|moussa)\\b\", 'diaby'],\n",
    "                                [r\"\\b(mykhaylo mudryk|mykhaylo)\\b\", 'mudryk'],\n",
    "                                [r\"\\b(amine adli|amine)\\b\", 'adli'],\n",
    "                                [r\"\\b(florian wirtz|florian)\\b\", 'wirtz'],\n",
    "                                [r\"\\b(jose mourinho|jose)\\b\", 'mourinho'],     \n",
    "                                #other wordgroups\n",
    "                                [r\"\\b(europa league)\\b\", 'europaleague'],\n",
    "                                [r\"\\b(champions league)\\b\", 'championsleague'],\n",
    "                                [r\"\\b(bayer leverkusen|bayer|leverkusen|leverkusens)\\b\", 'bayerleverkusen']\n",
    "                                ])\n",
    "\n",
    "    # do the pattern matching for each player\n",
    "    for pattern, player in pattern_match2d:\n",
    "        df['data'] = df['data'].apply(lambda x: re.sub(pattern, str(player), str(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence(df):\n",
    "    player_info_sentences = []\n",
    "    for idx, row in df.iterrows():\n",
    "        player = row['player']\n",
    "        entry = row['data']\n",
    "        sentences = re.split('\\. ', entry)\n",
    "        found_sentence = False\n",
    "        for sentence in sentences:\n",
    "            if player in sentence:\n",
    "                player_info_sentences.append(sentence)\n",
    "                found_sentence = True\n",
    "                break\n",
    "        if not found_sentence:\n",
    "            player_info_sentences.append('')\n",
    "    \n",
    "    df['sentence'] = player_info_sentences\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_de = pd.read_csv('../Preprocessing/data_clean/de_clean_1.csv')\n",
    "df_en = pd.read_csv('https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/Preprocessing/data_clean/en_clean_1.csv')\n",
    "df_en2 = pd.read_csv('https://raw.githubusercontent.com/svisel22/SS23-BIPM-Analytics-Lab---Group-4-repository/main/Preprocessing/data_clean/en_clean_2.csv')\n",
    "df_es = pd.read_csv('../Preprocessing/data_clean/es_clean_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         363 non-null    object\n",
      " 1   player       363 non-null    object\n",
      " 2   language     363 non-null    object\n",
      " 3   publishedAt  363 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         363 non-null    object\n",
      " 1   player       363 non-null    object\n",
      " 2   language     363 non-null    object\n",
      " 3   publishedAt  363 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep paragraph where the player name is found\n",
    "df_de = find_lines_with_player(df_de, df_de['player'].unique(),n_lines=1)\n",
    "df_en = find_lines_with_player(df_en, df_en['player'].unique(),n_lines=1)\n",
    "df_en2 = find_lines_with_player(df_en2, df_en2['player'].unique(),n_lines=1)\n",
    "df_es = find_lines_with_player(df_es, df_es['player'].unique(),n_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 363 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         363 non-null    object\n",
      " 1   player       363 non-null    object\n",
      " 2   language     363 non-null    object\n",
      " 3   publishedAt  363 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentence\n",
    "df_de = extract_sentence(df_de)\n",
    "df_en = extract_sentence(df_en)\n",
    "df_en2 = extract_sentence(df_en2)\n",
    "df_es = extract_sentence(df_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 363 entries, 0 to 20\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         363 non-null    object\n",
      " 1   player       363 non-null    object\n",
      " 2   language     363 non-null    object\n",
      " 3   publishedAt  363 non-null    object\n",
      " 4   sentence     363 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 17.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy sentence column into data and remove sentence\n",
    "df_de['data']= df_de['sentence']\n",
    "df_de.drop('sentence', axis=1, inplace=True)\n",
    "df_en['data']= df_en['sentence']\n",
    "df_en.drop('sentence', axis=1, inplace=True)\n",
    "df_en2['data']= df_en2['sentence']\n",
    "df_en2.drop('sentence', axis=1, inplace=True)\n",
    "df_es['data']= df_es['sentence']\n",
    "df_es.drop('sentence', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 363 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         363 non-null    object\n",
      " 1   player       363 non-null    object\n",
      " 2   language     363 non-null    object\n",
      " 3   publishedAt  363 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the similiar rows (The Function is imported from utils on top)\n",
    "df_de = remove_similar_rows_per_player(df_de, df_de['player'].unique())\n",
    "df_en = remove_similar_rows_per_player(df_en, df_en['player'].unique())\n",
    "df_en2 = remove_similar_rows_per_player(df_en2, df_en2['player'].unique())\n",
    "df_es = remove_similar_rows_per_player(df_es, df_es['player'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 143 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         143 non-null    object\n",
      " 1   player       143 non-null    object\n",
      " 2   language     143 non-null    object\n",
      " 3   publishedAt  143 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names in the text to unify player name to last name\n",
    "df_de = name_wordgroups(df_de)\n",
    "df_en = name_wordgroups(df_en)\n",
    "df_en2 = name_wordgroups(df_en2)\n",
    "df_es = name_wordgroups(df_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 143 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         143 non-null    object\n",
      " 1   player       143 non-null    object\n",
      " 2   language     143 non-null    object\n",
      " 3   publishedAt  143 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet empty rows\n",
    "df_de = df_de.replace('', pd.NA)\n",
    "df_de.dropna(inplace=True)\n",
    "\n",
    "df_en = df_en.replace('', pd.NA)\n",
    "df_en.dropna(inplace=True)\n",
    "\n",
    "df_en2 = df_en2.replace('', pd.NA)\n",
    "df_en2.dropna(inplace=True)\n",
    "\n",
    "df_es = df_es.replace('', pd.NA)\n",
    "df_es.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         136 non-null    object\n",
      " 1   player       136 non-null    object\n",
      " 2   language     136 non-null    object\n",
      " 3   publishedAt  136 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 135 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   data         135 non-null    object\n",
      " 1   player       135 non-null    object\n",
      " 2   language     135 non-null    object\n",
      " 3   publishedAt  135 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_en2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'en_clean_1_sen.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_en.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'en_clean_2_sen.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_en2.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'de_clean_1-1.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_de.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'es_clean_1-1.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_es.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
