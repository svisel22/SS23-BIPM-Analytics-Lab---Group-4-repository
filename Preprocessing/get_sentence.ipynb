{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import regex as re\n",
    "import os\n",
    "#sys.path.append('../')\n",
    "#from utils import find_lines_with_player, name_wordgroups, remove_similar_rows_per_player\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in utils. for joana\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function which finds the lines where a players name is contained\n",
    "def find_lines_with_player(dataframe, playerlist, n_lines = 0):\n",
    "    \n",
    "    # create empty df \n",
    "    df_complete = pd.DataFrame()\n",
    "\n",
    "    # iterating over all players\n",
    "    for player in playerlist:\n",
    "\n",
    "        # get players first and last_name to include them in later sentence checks\n",
    "        player_first_name, player_last_name = player.split()\n",
    "\n",
    "        # just select player indiviual data\n",
    "        df_player = dataframe[dataframe[\"player\"] == player]\n",
    "        df_player = df_player.reset_index(drop=True)\n",
    "\n",
    "        # iterate over all data for the player\n",
    "        for i in range(len(df_player)):\n",
    "\n",
    "            # get the current record\n",
    "            current_line = df_player['data'].iloc[i]\n",
    "            # split up the records in lines\n",
    "            lines = current_line.split('\\\\n')\n",
    "            # create an empty string\n",
    "            new_string = ''\n",
    "\n",
    "            line_counter = 0\n",
    "            # iterate over all lines in the record\n",
    "            for line in lines:\n",
    "                # if the playername can be found in the line add the line to the string\n",
    "                if line.find(player) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "            \n",
    "                elif line.find(player_first_name) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "        \n",
    "                elif line.find(player_last_name) != -1:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    if line_counter <= 0:\n",
    "                        line_counter = line_counter + n_lines\n",
    "            \n",
    "                elif line_counter >= 0:\n",
    "                    new_string = new_string + line + \" \"\n",
    "                    line_counter = line_counter-1\n",
    "        \n",
    "            # switch the previos record against the newly created string \n",
    "            df_player['data'].iloc[i] = new_string\n",
    "\n",
    "        # add the new data to the Dataframe and return\n",
    "        df_complete = pd.concat([df_complete, df_player], axis=0)\n",
    "        \n",
    "    return df_complete\n",
    "\n",
    "def remove_similar_rows_per_player(df, playerlist, threshold=0.9):\n",
    "    '''The procedure of deleting similiar articles needs to be done by each player because if an article writes about \n",
    "    # e.g. two players we want to keep it for both of the players'''\n",
    "\n",
    "    # define empty df which will be returned in the end\n",
    "    df_complete = pd.DataFrame()\n",
    "\n",
    "    for player in playerlist:\n",
    "        \n",
    "        # create the df for the player\n",
    "        df_player = df[df[\"player\"] == player]\n",
    "        df_player = df_player.reset_index(drop=True)\n",
    "        column_as_df = pd.DataFrame(df_player['data'])\n",
    "\n",
    "\n",
    "        \n",
    "        # Compute similarity scores for each pair of rows\n",
    "        similarity_scores = {}\n",
    "        for i, row in column_as_df.iterrows():\n",
    "            for j, other_row in column_as_df.iterrows():\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                score = SequenceMatcher(None, row, other_row).ratio()\n",
    "                if score >= threshold:\n",
    "                    similarity_scores[(i, j)] = score\n",
    "        \n",
    "        # Identify rows to remove\n",
    "        rows_to_remove = []\n",
    "        for (i, j), score in similarity_scores.items():\n",
    "            if i not in rows_to_remove and j not in rows_to_remove:\n",
    "                rows_to_remove.append(j if df_player.index[i] < df_player.index[j] else i)\n",
    "        \n",
    "        # Remove rows and concatenate df\n",
    "        df_player = df_player.drop(rows_to_remove)\n",
    "        df_complete = pd.concat([df_complete, df_player], axis=0)\n",
    "\n",
    "        #return modified DataFrame\n",
    "    return df_complete\n",
    "\n",
    "def name_wordgroups(df):\n",
    "    '''\n",
    "    Function to match first and surname to just last name\n",
    "    '''\n",
    "    # create patterns which should be matched \n",
    "    # first lastname and firstname should both result in just lastname\n",
    "    pattern_match2d = np.array([[r\"\\b(mitchel bakker|mitchel)\\b\", 'bakker'], \n",
    "                                [r\"\\b(xabi alonso|xabi)\\b\", 'alonso'], \n",
    "                                [r\"\\b(exequiel palacios|exequiel)\\b\", 'palacios'],\n",
    "                                [r\"\\b(nadiem amiri|nadiem)\\b\", 'amiri'],\n",
    "                                [r\"\\b(kerem demirbay|kerem)\\b\", 'demirbay'],\n",
    "                                [r\"\\b(robert andrich|robert)\\b\", 'andrich'],\n",
    "                                [r\"\\b(exequiel palacios|exequiel)\\b\", 'palacios'],\n",
    "                                [r\"\\b(piero hincapie|piero)\\b\", 'hincapie'],\n",
    "                                [r\"\\b(jeremie frimpong|jeremie)\\b\", 'frimpong'],\n",
    "                                [r\"\\b(jonathan tah|jonathan)\\b\", 'tah'],\n",
    "                                [r\"\\b(moussa diaby|moussa)\\b\", 'diaby'],\n",
    "                                [r\"\\b(mykhaylo mudryk|mykhaylo)\\b\", 'mudryk'],\n",
    "                                [r\"\\b(amine adli|amine)\\b\", 'adli'],\n",
    "                                [r\"\\b(florian wirtz|florian)\\b\", 'wirtz'],\n",
    "                                [r\"\\b(jose mourinho|jose)\\b\", 'mourinho'],     \n",
    "                                #other wordgroups\n",
    "                                [r\"\\b(europa league)\\b\", 'europaleague'],\n",
    "                                [r\"\\b(champions league)\\b\", 'championsleague'],\n",
    "                                [r\"\\b(bayer leverkusen|bayer|leverkusen|leverkusens)\\b\", 'bayerleverkusen']\n",
    "                                ])\n",
    "\n",
    "    # do the pattern matching for each player\n",
    "    for pattern, player in pattern_match2d:\n",
    "        df['data'] = df['data'].apply(lambda x: re.sub(pattern, str(player), str(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence(df):\n",
    "    player_info_sentences = []\n",
    "    for idx, row in df.iterrows():\n",
    "        player = row['player']\n",
    "        entry = row['data']\n",
    "        sentences = re.split('\\. ', entry)\n",
    "        found_sentence = False\n",
    "        for sentence in sentences:\n",
    "            if player in sentence:\n",
    "                player_info_sentences.append(sentence)\n",
    "                found_sentence = True\n",
    "                break\n",
    "        if not found_sentence:\n",
    "            player_info_sentences.append('')\n",
    "    \n",
    "    df['sentence'] = player_info_sentences\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_de = pd.read_csv('../Preprocessing/data_clean/de_clean_1.csv')\n",
    "df_en = pd.read_csv('../Preprocessing/data_clean/en_clean_1.csv')\n",
    "df_es = pd.read_csv('../Preprocessing/data_clean/es_clean_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep paragraph where the player name is found\n",
    "df_de = find_lines_with_player(df_de, df_de['player'].unique(),n_lines=1)\n",
    "df_en = find_lines_with_player(df_en, df_en['player'].unique(),n_lines=1)\n",
    "df_es = find_lines_with_player(df_es, df_es['player'].unique(),n_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names in the text to unify player name to last name\n",
    "df_de = name_wordgroups(df_de)\n",
    "df_en = name_wordgroups(df_en)\n",
    "df_es = name_wordgroups(df_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names in player column to keep only last name\n",
    "df_de = name_wordgroups(df_de)\n",
    "df_en = name_wordgroups(df_en)\n",
    "df_es = name_wordgroups(df_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentence\n",
    "df_de = extract_sentence(df_de)\n",
    "df_en = extract_sentence(df_en)\n",
    "df_es = extract_sentence(df_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy sentence column into data and remove sentence\n",
    "df_de['data']= df_de['sentence']\n",
    "df_de.drop('sentence', axis=1, inplace=True)\n",
    "df_en['data']= df_en['sentence']\n",
    "df_en.drop('sentence', axis=1, inplace=True)\n",
    "df_es['data']= df_es['sentence']\n",
    "df_es.drop('sentence', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the similiar rows (The Function is imported from utils on top)\n",
    "df_de = remove_similar_rows_per_player(df_de, df_de['player'].unique())\n",
    "df_en = remove_similar_rows_per_player(df_en, df_en['player'].unique())\n",
    "df_es = remove_similar_rows_per_player(df_es, df_es['player'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet empty rows\n",
    "df_de = df_de.replace('', pd.NA)\n",
    "df_de.dropna(inplace=True)\n",
    "\n",
    "df_en = df_en.replace('', pd.NA)\n",
    "df_en.dropna(inplace=True)\n",
    "\n",
    "df_es = df_es.replace('', pd.NA)\n",
    "df_es.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'en_clean_1_sen.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_en.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'en_clean_2_sen.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_en.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'de_clean_1-1.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_de.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'data_clean'\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_name = 'es_clean_1-1.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# Convert the dataframe to CSV and save it\n",
    "df_es.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
